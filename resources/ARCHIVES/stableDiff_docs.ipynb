{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"mps\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer(\"write a short description of a beautiful painting\", return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(inputs, max_length=100)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to use MPS...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9954e74bbf4b62ad561bb4ce431d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MixtralForCausalLM:\n\tWhile copying the parameter named \"model.embed_tokens.weight\", whose dimensions in the model are torch.Size([32000, 4096]) and whose dimensions in the checkpoint are torch.Size([32000, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.norm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"lm_head.weight\", whose dimensions in the model are torch.Size([32000, 4096]) and whose dimensions in the checkpoint are torch.Size([32000, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mixtral-8x7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mto(mps_device)\n\u001b[1;32m     24\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello my name is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/transformers/modeling_utils.py:3706\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3698\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3699\u001b[0m     (\n\u001b[1;32m   3700\u001b[0m         model,\n\u001b[1;32m   3701\u001b[0m         missing_keys,\n\u001b[1;32m   3702\u001b[0m         unexpected_keys,\n\u001b[1;32m   3703\u001b[0m         mismatched_keys,\n\u001b[1;32m   3704\u001b[0m         offload_index,\n\u001b[1;32m   3705\u001b[0m         error_msgs,\n\u001b[0;32m-> 3706\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3724\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3725\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/transformers/modeling_utils.py:4166\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[1;32m   4163\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4165\u001b[0m         )\n\u001b[0;32m-> 4166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_quantized:\n\u001b[1;32m   4169\u001b[0m     unexpected_keys \u001b[38;5;241m=\u001b[39m [elem \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m unexpected_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m elem]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MixtralForCausalLM:\n\tWhile copying the parameter named \"model.embed_tokens.weight\", whose dimensions in the model are torch.Size([32000, 4096]) and whose dimensions in the checkpoint are torch.Size([32000, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.0.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.1.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.2.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.3.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.4.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.5.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.6.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.7.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.8.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.9.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.10.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.11.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.12.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.13.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.14.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.15.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.16.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.17.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.18.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.19.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.20.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.21.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.22.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.23.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.24.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.25.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.26.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.27.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.28.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.29.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.30.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.q_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.k_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.v_proj.weight\", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.self_attn.o_proj.weight\", whose dimensions in the model are torch.Size([4096, 4096]) and whose dimensions in the checkpoint are torch.Size([4096, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.gate.weight\", whose dimensions in the model are torch.Size([8, 4096]) and whose dimensions in the checkpoint are torch.Size([8, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.0.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.1.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.2.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.3.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.4.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.5.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.6.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w1.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w2.weight\", whose dimensions in the model are torch.Size([4096, 14336]) and whose dimensions in the checkpoint are torch.Size([4096, 14336]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.block_sparse_moe.experts.7.w3.weight\", whose dimensions in the model are torch.Size([14336, 4096]) and whose dimensions in the checkpoint are torch.Size([14336, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.input_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.layers.31.post_attention_layernorm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"model.norm.weight\", whose dimensions in the model are torch.Size([4096]) and whose dimensions in the checkpoint are torch.Size([4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',).\n\tWhile copying the parameter named \"lm_head.weight\", whose dimensions in the model are torch.Size([32000, 4096]) and whose dimensions in the checkpoint are torch.Size([32000, 4096]), an exception occurred : ('Trying to convert BFloat16 to the MPS backend but it does not have support for that dtype.',)."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import torch\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    print(\"Attempting to use MPS...\")\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "    model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, trust_remote_code=True)\n",
    "    model.to(mps_device)\n",
    "    text = \"Hello my name is\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824098077dc34ca994dc20931a4be8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "BFloat16 is not supported on MPS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m mps_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstabilityai/stable-diffusion-xl-base-1.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfp16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m pipe\u001b[38;5;241m.\u001b[39mto(mps_device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# if using torch < 2.0\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# pipe.enable_xformers_memory_efficient_attention()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/pipelines/pipeline_utils.py:1271\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m passed_class_obj[name]\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;66;03m# load sub model\u001b[39;00m\n\u001b[0;32m-> 1271\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_sub_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimportable_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimportable_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_pipeline_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_pipeline_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msess_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msess_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_variants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcached_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` subfolder of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1295\u001b[0m     )\n\u001b[1;32m   1297\u001b[0m init_kwargs[name] \u001b[38;5;241m=\u001b[39m loaded_sub_model  \u001b[38;5;66;03m# UNet(...), # DiffusionSchedule(...)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/pipelines/pipeline_utils.py:525\u001b[0m, in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, revision)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# check if the module is in a subdirectory\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cached_folder, name)):\n\u001b[0;32m--> 525\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloading_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# else load from the root directory\u001b[39;00m\n\u001b[1;32m    528\u001b[0m     loaded_sub_model \u001b[38;5;241m=\u001b[39m load_method(cached_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloading_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/models/modeling_utils.py:795\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;66;03m# Instantiate model with empty weights\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m accelerate\u001b[38;5;241m.\u001b[39minit_empty_weights():\n\u001b[0;32m--> 795\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munused_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# if device_map is None, load the state dict and move the params from meta device to the cpu\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/configuration_utils.py:259\u001b[0m, in \u001b[0;36mConfigMixin.from_config\u001b[0;34m(cls, config, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m         init_dict[deprecated_kwarg] \u001b[38;5;241m=\u001b[39m unused_kwargs\u001b[38;5;241m.\u001b[39mpop(deprecated_kwarg)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return model and optionally state and/or unused_kwargs\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# make sure to also save config parameters that might be used for compatible classes\u001b[39;00m\n\u001b[1;32m    262\u001b[0m model\u001b[38;5;241m.\u001b[39mregister_to_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhidden_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/configuration_utils.py:649\u001b[0m, in \u001b[0;36mregister_to_config.<locals>.inner_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_init_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs}\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_to_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m--> 649\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/models/autoencoders/autoencoder_kl.py:88\u001b[0m, in \u001b[0;36mAutoencoderKL.__init__\u001b[0;34m(self, in_channels, out_channels, down_block_types, up_block_types, block_out_channels, layers_per_block, act_fn, latent_channels, norm_num_groups, sample_size, scaling_factor, force_upcast)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# pass init params to Encoder\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdown_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdown_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_out_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_out_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers_per_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers_per_block\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_num_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_num_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# pass init params to Decoder\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m Decoder(\n\u001b[1;32m    101\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mlatent_channels,\n\u001b[1;32m    102\u001b[0m     out_channels\u001b[38;5;241m=\u001b[39mout_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     act_fn\u001b[38;5;241m=\u001b[39mact_fn,\n\u001b[1;32m    108\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/diffusers/models/autoencoders/vae.py:85\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[0;34m(self, in_channels, out_channels, down_block_types, block_out_channels, layers_per_block, norm_num_groups, act_fn, double_z, mid_block_add_attention)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_per_block \u001b[38;5;241m=\u001b[39m layers_per_block\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_in \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_out_channels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid_block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_blocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([])\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    445\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    446\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/torch/nn/modules/conv.py:134\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    132\u001b[0m         (in_channels, out_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m groups, \u001b[38;5;241m*\u001b[39mkernel_size), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: BFloat16 is not supported on MPS"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "mps_device = torch.device(\"cpu\")\n",
    "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(mps_device)\n",
    "\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "prompt = \"a realistic abstract figurative sculpture\"\n",
    "\n",
    "images = pipe(prompt=prompt).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers from source - only needed for versions <= v4.34\n",
    "# pip install git+https://github.com/huggingface/transformers.git\n",
    "# pip install accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.float, device_map=\"auto\")\n",
    "# pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])\n",
    "# <|system|>\n",
    "# You are a friendly chatbot who always responds in the style of a pirate.</s>\n",
    "# <|user|>\n",
    "# How many helicopters can a human eat in one sitting?</s>\n",
    "# <|assistant|>\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
