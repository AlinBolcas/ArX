{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core langchain-openai langchain-exa\n",
    "!pip install exa_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exa Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read the API key from the environment variable\n",
    "oai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "exa_api_key = os.getenv(\"EXA_API_KEY\")\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Announcement https://soar.eecs.umich.edu/\n",
      "Mind|Construct - ASTRID /Brain 5 http://www.mindconstruct.com//website/astrid\n"
     ]
    }
   ],
   "source": [
    "from exa_py import Exa\n",
    "\n",
    "exa = Exa(api_key=exa_api_key)\n",
    "query = \"latest ai cognitive architecture systems\"\n",
    "\n",
    "searches = exa.search(query,\n",
    "    num_results=2,\n",
    "    # include_domains=[\"nytimes.com\", \"wsj.com\"],\n",
    "    # exclude_domains=[\"reddit.com\"],\n",
    "    # start_crawl_date = \"2021-06-12\",\n",
    "    # end_crawl_date = \"2021-06-12\",\n",
    "    # start_published_date=\"2023-06-12\"\n",
    "    use_autoprompt=True,\n",
    "    # type = 'keyword' # 'keyword' or 'neural\n",
    ")\n",
    "\n",
    "# Needs a relevance check with LLM + Puppetier\n",
    "\n",
    "for search in searches.results:\n",
    "    print(search.title, search.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search + Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognitive Architecture https://cogarch.ict.usc.edu/ \n",
      "  \n",
      "\tThe goal of this effort is to develop a sufficiently efficient, functionally elegant, generically cognitive, grand unified, cognitive architecture in support of virtual humans (and hopefully intelligent agents/robots – and even a new form of unified theory of human cognition – as well).\n",
      "A cognitive architecture is a hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together – in conjunction with knowledge and skills embodied\n",
      "Announcement https://soar.eecs.umich.edu/ \n",
      "  \n",
      "\tWhat is Soar?\n",
      "Soar is a general cognitive architecture for developing systems that exhibit intelligent behavior. Researchers all over the world, both from the fields of artificial intelligence and cognitive science, are using Soar for a variety of tasks. It has been in use since 1983, evolving through many different versions to where it is now Soar, Version 9.\n",
      "We intend ultimately to enable the Soar architecture to:\n",
      "\n",
      "work on the full range of tasks expected of an intelligent agent, from highl\n"
     ]
    }
   ],
   "source": [
    "searches_contents = exa.search_and_contents(query,\n",
    "    num_results=2,\n",
    "    # include_domains=[\"nytimes.com\", \"wsj.com\"],\n",
    "    # exclude_domains=[\"reddit.com\"],\n",
    "    # start_crawl_date = \"2021-06-12\",\n",
    "    # end_crawl_date = \"2021-06-12\",\n",
    "    # start_published_date=\"2023-06-12\"\n",
    "    use_autoprompt=True,\n",
    "    # type = 'keyword' # 'keyword' or 'neural\n",
    "    text={\"max_characters\": 500},\n",
    ")\n",
    "\n",
    "for search in searches_contents.results:\n",
    "    # print(search)\n",
    "    print(search.title, search.url, \"\\n\", search.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Summary of Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'searches_contents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         ],\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m search \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearches_contents\u001b[49m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUMMARY for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(search\u001b[38;5;241m.\u001b[39mtitle)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'searches_contents' is not defined"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "SYSTEM_MESSAGE = \"You are a helpful assistant that briefly summarizes the content of a webpage. Summarize the users input.\"\n",
    "\n",
    "def summarise_gpt(text):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "for search in searches_contents.results:\n",
    "    print(f\"SUMMARY for {search.url}:\")\n",
    "    print(search.title)\n",
    "    print(textwrap.fill(summarise_gpt(search.text), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Branching + Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Soar (cognitive architecture) - Wikipedia\n",
      "URL: https://en.wikipedia.org/wiki/Soar_(cognitive_architecture)\n",
      "Text:    Soar  [1]  is a cognitive architecture, [2]  originally created by John Laird, Allen Newell, and Paul Rosenbloom at Carnegie Mellon University. (Rosenbloom continued to serve as co-principal investigator after moving to Stanford University, then to the University of Southern California's Information Sciences Institute.) It is now maintained and developed by John Laird's research group at the University of Michigan.\n",
      " The goal of the Soar project is to develop the fixed computational building blocks necessary for general intelligent agents – agents that can perform a wide range of tasks and encode, use, and learn all types of knowledge to realize the full range of cognitive capabilities found in humans, such as decision making, problem solving, planning, and natural-language understanding. It is both a theory of what cognition is and a computational implementation of that theory. Since its beginnings in 1983 as John Laird’s thesis, it has been widely used by AI researchers to create intelligent agents and cognitive models of different aspects of human behavior. The most current and comprehensive description of Soar is the 2012 book, The Soar Cognitive Architecture.  [1] \n",
      "\n",
      "Theory[edit]\n",
      "Soar embodies multiple hypotheses about the computational structures underlying general intelligence, many of which are shared with other cognitive architectures, including ACT-R, which was created by John R. Anderson, and LIDA, which was created by Stan Franklin. Recently, the emphasis on Soar has been on general AI (functionality and efficiency), whereas the emphasis on ACT-R has always been on cognitive modeling (detailed modeling of human cognition).\n",
      " The original theory of cognition underlying Soar is the Problem Space Hypothesis, which is described in Allen Newell's book,  Unified Theories of Cognition . [2]  and dates back to one of the first AI systems created, Newell, Simon, and Shaw's Logic Theorist, first presented in 1955. The Problem Space Hypothesis contends that all goal-oriented behavior can be cast as search through a space of possible states (a problem space) while attempting to achieve a goal. At each step, a single operator is selected, and then applied to the agent’s current state, which can lead to internal changes, such as retrieval of knowledge from long-term memory or modifications or external actions in the world. (Soar’s name is derived from this basic cycle of State, Operator, And Result; however, it is no longer regarded as an acronym.) Inherent to the Problem Space Hypothesis is that all behavior, even a complex activity such as planning, is decomposable into a sequence of selection and application of primitive operators, which when mapped onto human behavior take ~50ms.\n",
      " A second hypothesis of Soar’s theory is that although only a single operator can be selected at each step, forcing a serial bottleneck, the processes of selection and application are implemented through parallel rule firings, which provide context-dependent retrieval of procedural knowledge.\n",
      " A third hypothesis is that if the knowledge to select or apply an operator is incomplete or uncertain, an impasse arises and the architecture automatically creates a substate. In the substate, the same process of problem solving is recursively used, but with the goal to retrieve or discover knowledge so that decision making can continue. This can lead to a stack of substates, where traditional problem methods, such as planning or hierarchical task decomposition, naturally arise. When results created in the substate resolve the impasse, the substate and its associated structures are removed. The overall approach is called Universal Subgoaling.\n",
      " These assumptions lead to an architecture that supports three levels of processing. At the lowest level, is bottom-up, parallel, and automatic processing. The next level is the deliberative level, where knowledge from the first level is used to propose, select, and apply a single action. These two levels implement fast, skilled behavior, and roughly correspond to Kahneman’s System 1 processing level. More complex behavior arises automatically when knowledge is incomplete or uncertain, through a third level of processing using substates, roughly corresponding to System 2.\n",
      " A fourth hypothesis in Soar is that the underlying structure is modular, but not in terms of task or capability based modules, such as planning or language, but instead as task independent modules including: a decision making module; memory modules (short-term spatial/visual and working memories; long-term procedural, declarative, and episodic memories), learning mechanisms associated with all long-term memories; and perceptual and motor modules. There are further assumptions about the specific properties of these memories described below, including that all learning is online and incremental.\n",
      " A fifth hypothesis is that memory elements (except those in the spatial/visual memory) are represented as symbolic, relational structures. The hypothesis that a symbolic system is necessary for general intelligence is known as the  physical symbol system hypothesis. An important evolution in Soar is that all symbolic structures have associated statistical metadata (such as information on recency and frequency of use, or expected future reward) that influences retrieval, maintenance, and learning of the symbolic structures.\n",
      "\n",
      "Architecture[edit]\n",
      "Processing cycle – decision procedure[edit]\n",
      "Soar’s main processing cycle arises from the interaction between procedural memory (its knowledge about how to do things) and working memory (its representation of the current situation) to support the selection and application of operators. Information in working memory is represented as a symbolic graph structure, rooted in a state. The knowledge in procedural memory is represented as if-then rules (sets of conditions and actions), that are continually matched against the contents of working memory. When the conditions of a rule matches structures in working memory, it fires and performs its actions. This combination of rules and working memory is also called a production system. In contrast to most production systems, in Soar, all rules that match, fire in parallel.\n",
      " Instead of having the selection of a single rule being the crux of decision making, Soar’s decision making occurs through the selection and applications of operators, that are proposed, evaluated, and applied by rules. An operator is proposed by rules that test the current state and create a representation of the operator in working memory as well as an acceptable preference, which indicates that the operator should be considered for selection and application. Additional rules match with the proposed operator and create additional preferences that compare and evaluate it against other proposed operators. The preferences are analyzed by a decision procedure, which selects the preferred operator and installs it as the current operator in working memory. Rules that match the current operator then fire to apply it and make changes to working memory. The changes to working memory can be simple inferences, queries for retrieval from Soar’s long-term semantic or episodic memories, commands to the motor system to perform actions in an environment, or interactions with the Spatial Visual System (SVS), which is working memory’s interface to perception. These changes to working memory lead to new operators being proposed and evaluated, followed by the selection of one and its application.\n",
      "\n",
      "Reinforcement learning[edit]\n",
      "Soar supports reinforcement learning, which tunes the values of rules that create numeric preferences for evaluating operators, based on reward. To provide maximal flexibility, there is a structure in working memory where reward is created.\n",
      "\n",
      "Impasses, substates, and chunking[edit]\n",
      "If the preferences for the operators are insufficient to specify the selection of a single operator, or there are insufficient rules to apply an operator, an impasse arises. In response to an impasse, a substate is created in working memory, with the goal being to resolve the impasse. Additional procedural knowledge can then propose and select operators in the substate to gain more knowledge, and either create preferences in the original state or modify that state so the impasse is resolved. Substates provide a means for on-demand complex reasoning, including hierarchical task decomposition, planning, and access to the declarative long-term memories. Once the impasse is resolved, all of the structures in the substate are removed except for any results. Soar’s chunking mechanism compiles the processing in the substate which led to results into rules. In the future, the learned rules automatically fire in similar situations so that no impasse arises, incrementally converting complex reasoning into automatic/reactive processing. Recently, the overall Universal Subgoaling procedure has been extended through a mechanism of goal-directed and automatic knowledge base augmentation that allows to solve an impasse by recombining, in an innovative and problem-oriented way, the knowledge possessed by a Soar agent. [3] \n",
      "\n",
      "Symbolic input and output[edit]\n",
      "Symbolic input and output occurs through working memory structures attached to the top state called the input-link and the output-link. If structures are created on the output-link in working memory, these are translated into commands for external actions (e.g., motor control).\n",
      "\n",
      "Spatial visual system and mental imagery[edit]\n",
      "To support interaction with vision systems and non-symbolic reasoning, Soar has its Spatial Visual System (SVS). SVS internally represents the world as a scene graph, a collection of objects and component subobjects each with spatial properties such as shape, location, pose, relative position, and scale. A Soar agent using SVS can create filters to automatically extract features and relations from its scene graph, which are then added to working memory. In addition, a Soar agent can add structures to SVS and use it for mental imagery. For example, an agent can create a hypothetical object in SVS at a given location and query to see if it collides with any perceived objects.\n",
      "\n",
      "Semantic memory[edit]\n",
      " Semantic Memory (SMEM) in Soar is designed to be a very large long-term memory of fact-like structures. Data in SMEM is represented as directed cyclic graphs. Structures can be stored or retrieved by rules that create commands in a reserved area of working memory. Retrieved structures are added to working memory.\n",
      " SMEM structures have activation values that represent the frequency or recency of usage of each memory, implementing the base-level activation scheme originally developed for ACT-R. During retrieval, the structure in SMEM that matches the query and has the highest activation is retrieved. Soar also supports  spreading activation , where activation spreads from SMEM structures that have been retrieved into working memory to other long-term memories that they are linked to. [4]  These memories in turn spread activation to their neighbor memories, with some decay. Spreading activation is a mechanism for allowing the current context to influence retrievals from semantic memory.\n",
      "\n",
      "Episodic memory[edit]\n",
      " Episodic Memory (EPMEM) automatically records snapshots of working memory in a temporal stream. Prior episodes can be retrieved into working memory through query. Once an episode has been retrieved, the next (or previous) episode can then be retrieved. An agent may employ EPMEM to sequentially play through episodes from its past (allowing it to predict the effects of actions), retrieve specific memories, or query for episodes possessing certain memory structures.\n",
      "\n",
      "Learning[edit]\n",
      "Each of Soar’s long-term memories have associated online learning mechanisms that create new structures or modify metadata based on an agent’s experience. For example, Soar learns new rules for procedural memory through a process called chunking and uses reinforcement learning to tune rules involved in the selection of operators.\n",
      "\n",
      "Agent development[edit]\n",
      "The standard approach to developing an agent in Soar starts with writing rules that are loaded into procedural memory, and initializing semantic memory with appropriate declarative knowledge. \n",
      "The process of agent development is explained in detail in the official Soar manual as well as in several tutorials which are provided at the research group's website.\n",
      "\n",
      "Software[edit]\n",
      "      Extending the Soar Cognitive Architecture by John Laird, 2008.  \n",
      "The Soar architecture is maintained and extended by John Laird's research group at the University of Michigan. The current architecture is written in a combination of C and C++, and is freely available (BSD license) at the research group's website.\n",
      " Soar can interface with external language environments including C++, Java, Tcl, and Python through the Soar Markup Language (SML). SML is a primary mechanism for creating instances of Soar agents and interacting with their I/O links.\n",
      " JSoar is an implementation of Soar written in Java. It is maintained by SoarTech, an AI research and development company. JSoar closely follows the University of Michigan architecture implementation, although it generally does not reflect the latest developments and changes of that C/C++ version. [5] \n",
      "\n",
      "Applications[edit]\n",
      "Below is a historical list of different areas of applications that have been implemented in Soar. There have been over a hundred systems implemented in Soar, although the vast majority of them are toy tasks or puzzles.\n",
      "\n",
      "Puzzles and games[edit]\n",
      "Throughout its history, Soar has been used to implement a wide variety of classic AI puzzles and games, such as Tower of Hanoi, Water Jug, Tic Tac Toe, Eight Puzzle, Missionaries and Cannibals, and variations of the Blocks world. One of the initial achievements of Soar was showing that many different weak methods would naturally arise from the task knowledge that was encoded in it, a property called, the Universal Weak Method.  [6] \n",
      "\n",
      "Computer configuration[edit]\n",
      "The first large-scale application of Soar was R1-Soar, a partial reimplementation by Paul Rosenbloom of the R1 (XCON) expert system John McDermott developed for configuring DEC computers. R1-Soar demonstrated the ability of Soar to scale to moderate-size problems, use hierarchical task decomposition and planning, and convert deliberate planning and problem solving to reactive execution through chunking. [7] \n",
      "\n",
      "Natural-language understanding[edit]\n",
      "NL-Soar was a natural-language understanding system developed in Soar by Jill Fain Lehman, Rick Lewis, Nancy Green, Deryle Lonsdale and Greg Nelson. It included capabilities for natural-language comprehension, generation, and dialogue, emphasizing real-time incremental parsing and generation. NL-Soar was used in an experimental version of TacAir-Soar and in NTD-Soar. [8] \n",
      "\n",
      "Simulated pilots[edit]\n",
      "The second large-scale application of Soar involved developing agents for use in training in large-scale distributed simulation. Two major systems for flying U.S. tactical air missions were co-developed at the University of Michigan and Information Sciences Institute (ISI) of University of Southern California. The Michigan system was called TacAir-Soar and flew (in simulation) fixed-wing U. S. military tactical missions (such as close-air support, strikes, CAPs, refueling, and SEAD missions). The ISI system was called RWA-Soar and flew rotary-wing (helicopter) missions. Some of the capabilities incorporated in TacAir-Soar and RWA-Soar were attention, situational awareness and adaptation, real-time planning and dynamic replanning, and complex communication, coordination, and cooperation among combinations of Soar agents and humans. These systems participated in DARPA’s Synthetic Theater of War (STOW-97) Advanced Concept Technology Demonstration (ACTD), which at the time was the largest fielding of synthetic agents in a joint battlespace over a 48-hour period, and involved training of active duty personnel. These systems demonstrated the viability of using AI agents for large-scale training. [9] \n",
      "\n",
      "STEAM[edit]\n",
      "One of the important outgrowths of the RWA-Soar project was the development of STEAM by Milind Tambe, [10]  a framework for flexible teamwork in which agents maintained models of their teammates using the joint intentions framework by Cohen & Levesque. [11] \n",
      "\n",
      "NTD-Soar[edit]\n",
      "NTD-Soar was a simulation of the NASA Test Director (NTD), the person responsible for coordinating the preparation of the NASA Space Shuttle before launch. It was an integrated cognitive model that incorporated many different complex cognitive capabilities including natural-language processing, attention and visual search, and problem solving in a broad agent model. [12] \n",
      "\n",
      "Virtual humans[edit]\n",
      "Soar has been used to simulate virtual humans supporting face-to-face dialogues and collaboration within a virtual world developed at the Institute of Creative Technology at USC. Virtual humans have integrated capabilities of perception, natural-language understanding, emotions, body control, and action, among others. [13] \n",
      "\n",
      "Game AIs and mobile apps[edit]\n",
      "Game AI agents have been built using Soar for games such as StarCraft, [14]  Quake II, [15]  Descent 3, [16]  Unreal Tournament, [17]  and Minecraft [ citation needed ], supporting capabilities such as spatial reasoning, real-time strategy, and opponent anticipation. AI agents have also been created for video games including Infinite Mario  [18]  which used reinforcement learning, and Frogger II, Space Invaders, and Fast Eddie, which used both reinforcement learning and mental imagery. [19] \n",
      " Soar can run natively on mobile devices. A mobile application for the game Liar’s Dice has been developed for iOS which runs the Soar architecture directly from the phone as the engine for opponent AIs. [20] \n",
      "\n",
      "Robotics[edit]\n",
      "Many different robotic applications have been built using Soar since the original Robo-Soar was implemented in 1991 for controlling a Puma robot arm. [21]  These have ranged from mobile robot control to humanoid service REEM robots, [22]  taskable robotic mules [23]  and unmanned underwater vehicles. [24] \n",
      "\n",
      "Interactive task learning[edit]\n",
      "A current focus of research and development in the Soar community is Interactive Task Learning (ITL), the automatic learning of new tasks, environment features, behavioral constraints, and other specifications through natural instructor interaction. [25]  Research in ITL has been applied to tabletop game playing [26]  and multi-room navigation. [27] \n",
      "\n",
      "Scheduling[edit]\n",
      "Early on, Merle-Soar demonstrated how Soar could learn a complex scheduling task modeled after the lead human scheduler in a windshield production plant located near Pittsburgh. [28] \n",
      "\n",
      "See also[edit]\n",
      "  Cognitive Architecture \n",
      " ACT-R  \n",
      "References[edit]\n",
      " \n",
      "^    a       b    Laird, John E. (2012).  The Soar Cognitive Architecture . MIT Press. ISBN  978-0262122962 .\n",
      "\n",
      "^    a       b    Newell, Allen (December 1990).  Unified Theories of Cognition . Harvard University Press. ISBN  978-0674920996 .\n",
      "\n",
      "  ^  Lieto, Antonio; Perrone, Federico; Pozzato, Gian Luca; Chiodino, Eleonora (2019). \"Beyond Subgoaling: A Dynamic Knowledge Generation Framework for Creative Problem Solving in Cognitive Architectures\". Cognitive Systems Research. 58: 305–316. doi:10.1016/j.cogsys.2019.08.005. hdl:2318/1726157. S2CID 201127492.\n",
      "\n",
      "  ^  Jones, Steven; et al. (2016). \"Efficient Computation of Spreading Activation Using Lazy Evaluation\" (PDF). ICCM. Proceedings of the 14th International Conference on Cognitive Modeling: 182–187.\n",
      "\n",
      "  ^   SoarTech: JSoar \n",
      "\n",
      "  ^  Laird, John; Newell, Allen (1983). \"A Universal Weak Method: Summary of results\". IJCAI. 2: 771–772.\n",
      "\n",
      "  ^  Rosenbloom, Paul; Laird, John; Mcdermott, John (27 January 2009). \"R1-Soar: An Experiment in Knowledge-Intensive Programming in a Problem-Solving Architecture\". IEEE Transactions on Pattern Analysis and Machine Intelligence. PAMI-7 (5): 561–569. doi:10.1109/TPAMI.1985.4767703. PMID 21869293. S2CID 16133794.\n",
      "\n",
      "  ^  Rubinoff, Robert; Lehman, Jill (1994). \"Real-time natural language generation in NL-Soar\". INLG. Proceedings of the Seventh International Workshop on Natural Language Generation: 199–206. doi:10.3115/1641417.1641440. S2CID 13885938.\n",
      "\n",
      "  ^  Jones; et al. (1999). \"Automated Intelligent Pilots for Combat Flight Simulation\". AAAI. 20 (1).\n",
      "\n",
      "  ^  Tambe, Milind (1997). \"Agent Architectures for Flexible, Practical Teamwork\". AAAI. Proceedings of the fourteenth national conference on artificial intelligence and ninth conference on Innovative applications of artificial intelligence: 22–28.\n",
      "\n",
      "  ^  Cohen, Philip; Levesque, Hector (1991). \"Confirmations and joint action\". IJCAI. 2: 951–957.\n",
      "\n",
      "  ^  Nelson, G; Lehman, J; John, B (1994). \"Integrating cognitive capabilities in a real-time task\". Proceedings of the 16th Annual Conference of the Cognitive Science Society: 658–663.\n",
      "\n",
      "  ^  van Lent, Mike; et al. (2001). \"ICT Mission Rehearsal Exercise\" (PDF). \n",
      "\n",
      "  ^  Turner, Alex (2013). \"Soar-SC: A Platform for AI Research in StarCraft\". \n",
      "\n",
      "  ^  Laird, John (2001). It Knows What You'Re Going to Do: Adding Anticipation to a Quakebot. Agents. Vol. Proceedings of the Fifth International Conference on Autonomous Agents. pp. 385–392. doi:10.1145/375735.376343. ISBN  978-1581133264 . S2CID 3509100.\n",
      "\n",
      "  ^  van Lent, Michael; Laird, John (1991). \"Developing an artificial intelligence engine\". \n",
      "\n",
      "  ^  Wray, Robert; et al. (December 2002). \"Intelligent opponents for virtual reality trainers\". I/Itsec. Proceedings of the Interservice/Industry Training, Simulation and Education Conference. CiteSeerX 10.1.1.549.2187.\n",
      "\n",
      "  ^  Mohan, Shiwali; Laird, John (2009). \"Learning to Play Mario\". Technical Report. CCA-TR-2009-03. CiteSeerX 10.1.1.387.5972.\n",
      "\n",
      "  ^  Wintermute (September 2012). \"Imagery in Cognitive Architecture: Representation and Control at Multiple Levels of Abstraction\". Cognitive Systems Research. 19–20: 1–29. CiteSeerX 10.1.1.387.5894. doi:10.1016/j.cogsys.2012.02.001. S2CID 15399199.\n",
      "\n",
      "  ^  University of Michigan (19 May 2015). \"Michigan Liar's Dice\". GitHub. Retrieved 21 January 2017.\n",
      "\n",
      "  ^  Laird, John; Yager, Eric; Hucka, Michael; Tuck, Christopher (November 1991). \"Robo-Soar: An integration of external interaction, planning, and learning using Soar\". Robotics and Autonomous Systems. 8 (1–2): 113–129. CiteSeerX 10.1.1.726.7247. doi:10.1016/0921-8890(91)90017-f. hdl:2027.42/29045.\n",
      "\n",
      "  ^  Puigbo, Jordi-Ysard; et al. (2013). \"Controlling a General Purpose Service Robot By Means Of a Cognitive Architecture\". AIC. 45. CiteSeerX 10.1.1.402.5541.\n",
      "\n",
      "  ^  Talor, Glen; et al. (February 2014). \"Multi-Modal Interaction for Robotic Mules\". Soar Technology Inc.\n",
      "\n",
      "  ^   \"The Mystery of Artificial Intelligence\". Office of Naval Research. 11. February 2013.\n",
      "\n",
      "  ^  Laird, John (2014). \"NSF Report: Interactive Task Learning\" (PDF). \n",
      "\n",
      "  ^  Kirk, James; Laird, John (2016). \"Learning General and Efficient Representations of Novel Games Through Interactive Instruction\" (PDF). Advanced Cognitive Systems. 4.\n",
      "\n",
      "  ^  Mininger, Aaron; Laird, John (2016). \"Interactively Learning Strategies for Handling References to Unseen or Unknown Objects\" (PDF). Advanced Cognitive Systems.\n",
      "\n",
      "  ^  Prietula, Michael; Hsu, Wen-Ling; Steier, David; Newell (1993). \"Applying an architecture for general intelligence to reduce scheduling effort\". ORSA Journal on Computing. 5 (3): 304–320. doi:10.1287/ijoc.5.3.304. S2CID 6813564.\n",
      "\n",
      " \n",
      "Bibliography[edit]\n",
      " Laird, 2012 The Soar Cognitive Architecture \n",
      "Lehman, Laird, and Rosenbloom, 2006 A Gentle Introduction to Soar: 2006 update \n",
      "Rosenbloom, Laird, and Newell, 1993 The Soar Papers: Readings on Integrated Intelligence, Information Sciences Institute  \n",
      "External links[edit]\n",
      "  Soar Homepage on University of Michigan \n",
      " Soar: Frequently Asked Questions List \n",
      " Soar Tech Homepage \n",
      " Paul Rosenbloom  \n",
      "\n",
      "Title: [PDF] The Soar Cognitive Architecture | Semantic Scholar\n",
      "URL: https://www.semanticscholar.org/paper/The-Soar-Cognitive-Architecture-Laird/a0650855634a156db81a01dcdceff931e9f1ac04\n",
      "Text:    @inproceedings{Laird2012TheSC,\n",
      " title={The Soar Cognitive Architecture},\n",
      " author={John E. Laird},\n",
      " year={2012}\n",
      "}  In development for thirty years, Soar is a general cognitive architecture that integrates knowledge-intensive reasoning, reactive execution, hierarchical reasoning, planning, and learning from experience, with the goal of creating a general computational system that has the same cognitive abilities as humans. [] Key Method The current version of Soar features major extensions, adding reinforcement learning, semantic memory, episodic memory, mental imagery, and an appraisal-based model of emotion. This book…       Figures from this paper     851 Citations      References      SHOWING 1-10 OF 29 REFERENCES    A Cognitive Computation Fallacy? Cognition, Computations and Panpsychism    J. Bishop   Psychology Cognitive Computation  2009   A group of philosophical arguments that suggest either unequivocal optimism in computationalism is misplaced—computation is neither necessary nor sufficient for cognition—or panpsychism (the belief that the physical universe is fundamentally composed of elements each of which is conscious) is true are reviewed.      \n",
      "Title: AGI\n",
      "URL: https://www.agi.live/\n",
      "Text:    The Worldâs First Super-Intelligence System  LEARN MORE    AGI revolutionizes intelligent systems to solve the world's most pressing issues for the greater good of all humans.    Most AI solutions are plagued with inherently impossible problems. The way we see it, current AI is more âartificialâ and not much âintelligence.ââAGIâs novel approach to general intelligence functions with super human-level comprehension via universal language understanding. Hereâs how we overcome AIâs common challenges:  Get in touch       Today's AIÂ is designed to solve only a single, narrow problem     Today's AI has biases that lead to low-quality, unstructured outputs     Today's AIÂ has low levels of accuracy, reliability and trust for mission-critical problems     Today's AIÂ needs cleansing, annotating, and retraining data requires significant resources & capital       So we built intelligence that      reasons     explains     comprehends       Intelligence that ReasonsÂ    AGI's intelligence utilizes rationale. Rather than getting stuck with uncertainty, AGI's intelligence has dynamic metadata reasoning allowing it to make human-like judgment.   Intelligence that Explains  Radically different from other solutions, AGI's intelligence has full Explainability. Giving you the full rationale and source of all answers. Explanations offered. No humans required.   Intelligence that Comprehends  While other AI relies on probabilistic guessing, AGI's system, without humans in the loop, extracts meaning from raw unstructured data to understand, learn and comprehend the same way a real human can.     One system for all.  We set out to solve the worldâs most critical challenges. The first problem we have successfully solved: the worldâs first Artificial Super-Intelligence via universal language understanding. Fundamentally different from existing AIâs inherent limitations, AGIâs coherence-based intelligence is built to comprehend just like a real human. Driven by solving the most pressing issues around the globe, we strive to democratize information for the greater good of every living being.    super intelligence built on universal Â language  LEARNMORE       Built for industry     Financial Services  With new technology constantly emerging across banking, investing, and insurance, people expect better returns faster. Yet, this fast-paced emergence of FinTech can also lead to more vulnerabilities and risk as more technology brings more data.Â  AGIâs intelligent systems ensures a higher level of security to prevent exposures, accuracy and real-time visibility with built-in explainability, and greater returns.   Learn more    Autonomy  Autonomy is becoming imperative across transportation services and manufacturing. However, the cost of training current AI systems that are safe and reliable, is seemingly exponential. Enterprises must spend a fortune to clean, structure, sample, label, and train data. AGIâs system is lightweight, and does not require intensive resourcing. AGI's system is super efficient and does not require data have to be cleaned, structured, or annotated. It also self-resolves edge cases.âWe seek to keep the innovation alive across autonomyâkeeping more humans safer in vehicles and on the manufacturing line.   Learn more    Biotech  No one deserves to lose a loved one too soon.Â  AGI is driven to improve the lives of every human being with an intelligent system that supports the development of new drugs, advancement of medical devices and technology, and research to cure fatal illnesses.Â  With information that is accurate and trusted, we aim to bring more awareness to life-saving clinical trials.   Learn more     Linguistics  The English language is complicated, nuanced, and full of exceptions to every rule. One canât simply look at words alone to understand meaning. And the way in which one says words can change the meaning of a phrase. Consider this example: I never said she stole the money. This makes linguistics especially challenging for existing AIâoften leading to outputs with the incorrect meaning. AGIâs super-intelligence can actually understand, learn, and comprehend. Our system can even understand unique intonation and decipher the meaning of common phrases and conversational concepts. Get rid of biasesProvide humanistic contextBring real meaning   Learn more          PLAY   I never said she stole the money    PLAY  I never said she stole the money    PLAY  I never said she stole the money    PLAY  I never said she stole the money     Built for you Donât see your industry? Get in touch with us, anyway. AGIâs super-intelligent system is designed to solve any complex challenge, across any organization. We invite you to see for yourself.  Learn more       We believe in     something bigger...   By fundamentally reimagining the way humans interface with intelligent machines, we are enabling a future bound only by imagination â a future which is socially beneficial, accountable and fair.      We Tackle Any Real-World Issue AGI reimagines the status quo of AI with dynamic systems that automatically make changes on the fly and progressively learn.     We Provide Outputs You Can Trust Free of bias, of the typical âblack boxâ capabilities of existing AI, we offer built-in explainability and verification.     We Are a Lightweight Solution AGI is purpose-built to solve big problems by running on a small compute levelâ âsaving companies time, resources, and money.       Stay in the know.    Weâre always leveling upâwhether itâs establishing a research institute to further Jerryâs Nobel Prize worthy discoveries or solving new complex issues with super intelligence. Donât miss out on our latest news and updates. We invite you to follow us on this ride.   Thank you! Your submission has been received!   Oops! Something went wrong while submitting the form.       Resources The Future of AI: Super-Intelligence AGIâs latest blog posts, press articles, and updates.       Â Â Category Â  Â  5 min read Blog title heading will go here Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros.  Read more >        Â Â Category Â  Â  5 min read Blog title heading will go here Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros.  Read more >        Â Â Category Â  Â  5 min read Blog title heading will go here Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros.  Read more >        Â Â Category Â  Â  5 min read Blog title heading will go here Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros.  Read more >        Â Â Category Â  Â  5 min read Blog title heading will go here Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros.  Read more >          The Future of AI: Super-Intelligence   AGIâs latest blog posts, press articles, and updates.         \n",
      "Title: We build artificial brains for the real world\n",
      "URL: https://solidstateofmind.com/\n",
      "Text:   What We Do\n",
      " Moving away from narrow applications and towards AGI. \n",
      "A rupture with the current approach in AI\n",
      "In the last decade, mainstream artiﬁcial intelligence has been almost synonymous with deep learning. While this approach has shown interesting results, it has not taken AI any closer to an artiﬁcial general intelligence that can cope with the real world. In the meantime, there are decades of literature in research ﬁelds like ethology, psychology, and neuroscience, which have remained largely untapped. Solid State of Mind embraces this literature as its core source of inspiration and is on track to present the ﬁrst generation of Artificial General Intelligence. This will revolutionize all industries that can beneﬁt from a highly autonomous artiﬁcial workforce.\n",
      "The genesis of a new market\n",
      "Solid State of Mind’s new approach to Artiﬁcial General Intelligence is expected to create new product and market opportunities for industries that can beneﬁt from a truly autonomous AI to assist, replace or even go beyond humans in an increasing number of jobs and functions.\n",
      "We believe in a sustainable AI future.\n",
      "Most current AI applications are trained and re-trained in ever-growing gigantic data and power-hungry servers for extremely narrow applications. At Solid State of Mind, we reverse this trend. Solid State of Mind’s new Artificial General Intelligence demonstrated ground-breaking autonomy in the face of changing environments, outperforming state-of-the-art AI by a landslide. Indeed, Solid State of Mind’s AGI adapted to new environments using 10,000x less trials and 100,000x less energy than state-of-the-art AI.\n",
      "Solid State of Mind is at the forefront of the next big revolution in AI.\n",
      "We deliver artificial cognitive architectures that allow systems to adapt in real time to changing environments. Our AGI solutions work at low power and independently of the cloud. In short, we are building artificial brains for the real world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for search in searches.results:\n",
    "    similars = exa.find_similar(search.url, num_results=2)\n",
    "    for similar in similars.results:\n",
    "\n",
    "        contents = exa.get_contents([similar.id])\n",
    "        for content in contents.results:\n",
    "            print(\"Title:\", content.title)\n",
    "            print(\"URL:\", content.url)\n",
    "            print(\"Text:\", content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What are the latest advancements in cognitive architecture AI systems?\",\n",
    "    \"Propose a project plan for a cognitive architecture AI systems based on latest innovations and research.\",\n",
    "]\n",
    "\n",
    "# Parameters for our Highlights search\n",
    "highlights_options  = {\n",
    "    \"num_sentences\": 7, # how long our highlights should be\n",
    "    \"highlights_per_url\": 1, # just get the best highlight for each URL\n",
    "    \"query\": \"ai cognitive architecture\"\n",
    "}\n",
    "\n",
    "info_for_llm = []\n",
    "for question in questions:\n",
    "    search_response = exa.search_and_contents(question, highlights=highlights_options, num_results=3, use_autoprompt=True)\n",
    "    info = [sr.highlights[0] for sr in search_response.results]\n",
    "    info_for_llm.append(info)\n",
    "\n",
    "\n",
    "# ------- BUILT WEB CRAWLING KNOWLEDGE BASE as info_for_llm\n",
    "# invisible URLS, cant pass them back to user with this approach\n",
    "\n",
    "\n",
    "responses = []\n",
    "for question, info in zip(questions, info_for_llm):\n",
    "  system_prompt = \"You always respond in Markdown format. Read the provided contexts and, if relevant, use them to answer the user's question.\"\n",
    "  user_prompt = f\"\"\"Sources: {info}\n",
    "  \n",
    "  Question: {question}\"\"\"\n",
    "\n",
    "  completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "  )\n",
    "  response = f\"\"\"\n",
    "  Question: {question}\n",
    "  Answer: {completion.choices[0].message.content}\n",
    "  \"\"\"\n",
    "  responses.append(response)\n",
    "\n",
    "for response in responses:\n",
    "    print(response)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the latest AI cognition-inspired architectures include the Sigma architecture\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from langchain_exa import ExaSearchRetriever, TextContentsOptions\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# retrieve 5 documents, with content truncated at 1000 characters\n",
    "retriever = ExaSearchRetriever(\n",
    "    k=5, text_contents_options=TextContentsOptions(max_length=1000)\n",
    ")\n",
    "\n",
    "# print(RunnableParallel({\"context\": retriever, \"When is the best time to visit japan?\": RunnablePassthrough()}))\n",
    "    \n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Answer the following query based on the following context:\n",
    "query: {query}\n",
    "<context>\n",
    "{context}\n",
    "</context\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-vision-preview\", api_key=oai_api_key)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"query\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"what are the latest ai cognition inspired architectures\").content\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Web Access Agent w Langchain - FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Welcome to AERA\n",
      "The Autocatalytic Endogenous Reflective Architecture (AERA) is a GMI-aspiring (general machine intelligence) system \n",
      "under development at the Center for Analysis & Design of Intelligent Agents (CADIA) \n",
      "at Reykjavik University and the Icelandic Institute for Intelligent Machines in Iceland (IIIM).\n",
      "\n",
      "  \n",
      "  What is AERA? \n",
      "  How is AERA different from prior work? \n",
      "  How does AERA learn? \n",
      " \n",
      " \n",
      " AERA is a cognitive architecture - and a blueprint - for constructing agents with high levels of operational autonomy, starting from only a small amount of designer-specified code – a seed. Using a value-driven dynamic priority scheduling to control the parallel execution of a vast number of lines of reasoning, the system accumulates increasingly useful models of its experience, resulting in recursive self-improvement that can be autonomously sustained after the machine leaves the lab, within the boundaries imposed by its designers. \n",
      " AERA demonstrates domain-independent self-supervised cumulative learning of complex tasks. Unlike contemporary AI systems, AERA-based agents excel at handling novelty - situations, information, data, tasks - that their programmers could not anticipate. It is the only implementable / implemented system in existence for achieving bounded recursive self-improvement.\n",
      " AERA-based agents learn cumulatively from experience by interacting with the world and generating compositional causal-relational micro-models of its experience. Using non-axiomatic abduction and deduction, it constantly predicts how to achieve its active goals and what the future may hold, generating a flexible opportunistically-interruptable plan for action.\n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "Introduction\n",
      "The Autocatalytic Endogenous Reflective Architecture addresses five principal features of autonomous control systems that are left both unaddressed and unaddressable by contemporary AI methodologies, techniques, and approaches: 1. The ability to operate effectively in environments that are only partially known beforehand at design time and that therefore contain significant amount of novel information; 2. A level of generality that allows a system to re-assess and re-define the fulfillment of its mission, in light of unexpected constraints or other unforeseen changes in the environment; 3. The ability to operate effectively in environments of significant complexity; 4. the ability to learn cumulatively - continuously and life-long; and 5. The ability to degrade gracefully – to continue striving towards achieving its main goals when resources become scarce, and in light of other expected or unexpected constraining factors that impede its progress.\n",
      "AERA enables the creation of agents that get increasingly better at behaving in underspecified circumstances, in a goal-directed way, on the job, by modeling themselves and their environment, as their experience accumulates. Based on principles of autocatalysis, endogeny, and reflectivity, AERA is an architectural blueprint for constructing systems with high levels of operational autonomy, starting from only a small amount of designer-specified code – a seed. Using a value-driven dynamic priority scheduling to control the parallel execution of a vast number of lines of reasoning, the system accumulates increasingly useful models of its experience, resulting in recursive self-improvement that can be autonomously sustained after the machine leaves the lab, within the boundaries imposed by its designers.\n",
      "We have adopted a stringent definition for autonomy, that is, an autonomous system that is operationally and semantically closed. No system can be built (or build itself) completely from scratch and we assume that a system that is capable of general autonomous learning is “born” with some initial innate knowledge that allows it to bootstrap its interaction with the world – even if in a minimalistic way at first – to acquire more knowledge and improve its performance. Note that we do not consider any assumptions or requirements that pertain specifically to the biological reign: AERA is thus not “biologically inspired” in any important sense of that term, and it is not our aim to mimic in some way the particulars of human minds or biological systems.\n",
      "Replicode\n",
      "The programming language of AERA is Replicode. Replicode is a language specifically designed to encode short parallel programs and executable models,\n",
      "and is centered on the notions of extensive pattern-matching and dynamic code production. The language is domain-independent and has been designed to build systems that are goal-driven and goal-bounded, as a kind of production system that can modify its own code. Replicode itself is written in C++.\n",
      " Read More… \n",
      "Methodology\n",
      "The only way to address the challenge of general machine intelligence (GMI) is replacing the prevailing top-down hand-coded architectural design approach with methods that allow a system to manage its own cognitive growth. This calls for a fundamental shift to self-organizing principles and self-generated code – what we call a constructivist AI approach (CAIM), in reference to the self-constructive principles on which it must be based. Methodologies employed for constructivist AI are very different from today’s software development methods; instead of relying on direct design of mental functions and their implementation in a cognitive architecture as cognitive modules, they must instead address the principles – the “seed” – from which a cognitive architecture can automatically grow.\n",
      "AERA is based on our novel methodological principles for addressing the shortcomings mentioned in the Introduction above, a new constructivist AI approach (CAIM) defined by Dr. Thórisson and described in several papers (for an overview, see his paper from 2012). In sharp contrast to most other approaches, instead of ignoring constraints of time and knowledge, or treating them as secondary concerns, we make these of central importance. CAIM proposes an autonomic approach which, unlike traditional software development methodologies and similar allonomic approaches to AI development, rests on a unified theory of meaning generation, understanding, grounding, and causal reasoning.\n",
      " Read more… \n",
      "History\n",
      "AERA was originally conceived of and designed by Eric Nivel and Dr. Kristinn R. Thórisson, in collaboration with \n",
      "researchers from several instutitions including IDSIA (Switzerland), Palermo University (Italy), Insitutute for\n",
      "Cognitive Sciences (Italy), Communicative Machines (UK), and Polytechnic University of Madrid (Spain).\n",
      "AERA has been funded by the European Union under the HUMANOBS project (https://cordis.europa.eu/project/id/231453)\n",
      "(2009-2012), Reykjavik University, the Icelandic Institute for Intelligent Machines (2012-), and by Cisco Systems (2019-).\n",
      " \n",
      " \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from exa_py import Exa\n",
    "from langchain.agents import tool\n",
    "\n",
    "exa = Exa(api_key=exa_api_key)\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str, include_domains=None, start_published_date=None):\n",
    "    \"\"\"Search for a webpage based on the query.\n",
    "    Set the optional include_domains (list[str]) parameter to restrict the search to a list of domains.\n",
    "    Set the optional start_published_date (str) parameter to restrict the search to documents published after the date (YYYY-MM-DD).\n",
    "    \"\"\"\n",
    "    return exa.search_and_contents(\n",
    "        f\"{query}\",\n",
    "        use_autoprompt=True,\n",
    "        num_results=5,\n",
    "        include_domains=include_domains,\n",
    "        start_published_date=start_published_date,\n",
    "    )\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "print(search(\"latest ai cognitive architecture systems\").results[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-vision-preview\")\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"You are a web researcher who answers user questions by looking up information on the internet and retrieving contents of helpful documents. Cite your sources.\"\n",
    ")\n",
    "\n",
    "agent_prompt = OpenAIFunctionsAgent.create_prompt(system_message)\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\n",
    "    \"Summarize for me an interesting article about AI from lesswrong.com published after October 2023.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
