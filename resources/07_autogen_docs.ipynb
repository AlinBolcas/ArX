{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "\n",
    "import autogen\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read the API key from the environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "config_list =[\n",
    "    {\n",
    "        \"model\": \"gpt-4-1106-preview\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"ollama\",\n",
    "        \"api_key\": \"NULL\",\n",
    "        \"base_url\": \"http://0.0.0.0:8000 \"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"output\": \"coding\"}, human_input_mode=\"NEVER\", max_consecutive_auto_reply=1)\n",
    "user_proxy.initiate_chat(assistant, message=\"how do i increase longevity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import OpenAIWrapper\n",
    "\n",
    "client = OpenAIWrapper(config_list=config_list)\n",
    "\n",
    "response = client.create(messages=[{\"role\": \"user\", \"content\": \"write a short bullet point of how to live forever\"}])\n",
    "\n",
    "print(client.extract_text_or_completion_object(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant and Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "gpt_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 1.2,\n",
    "    # \"max_tokens\": 100,\n",
    "    # \"timeout\": 120,\n",
    "    # \"cache_seed\": 41,  # change the seed for different trials\n",
    "}\n",
    "\n",
    "ollama_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 100,\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0,\n",
    "    \"cache_seed\": 43,\n",
    "}\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"socrates\",\n",
    "    llm_config=ollama_config,\n",
    "    system_message=\"You are Socrates.\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"admin\",\n",
    "    system_message=\"You are a gen X admin never happy with anything. Always complaining.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    # max_consecutive_auto_reply=0,\n",
    "    code_execution_config= False, # { \"work_dir\": \"work_dir\", \"use_docker\": False,},\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(assistant, user_proxy, message=\"debate the topic of modern western lifestyle vs ancient athenian lifestyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import OpenAIWrapper\n",
    "\n",
    "client = OpenAIWrapper()\n",
    "client.create(messages=[{\"role\": \"user\", \"content\": \"Python learning tips.\"}], model=\"gpt-3.5-turbo\")\n",
    "client.print_usage_summary()  # Display usage\n",
    "client.clear_usage_summary()  # Reset usage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "ollama_config = {\n",
    "    \"config_list\":[\n",
    "        {\n",
    "            \"model\": \"ollama\",\n",
    "            \"api_key\": \"NULL\",\n",
    "            \"base_url\": \"http://0.0.0.0:8000\"\n",
    "        },\n",
    "    ],\n",
    "    \"timeout\": 120,\n",
    "    \"max_tokens\": 10,\n",
    "    \"temperature\": 0,\n",
    "    \"cache_seed\": 43,\n",
    "}\n",
    "\n",
    "engineer_config = {\n",
    "    \"config_list\":[\n",
    "        {\n",
    "            \"model\": \"ollama\",\n",
    "            \"api_key\": \"NULL\",\n",
    "            \"base_url\": \"http://0.0.0.0:8000\"\n",
    "        },\n",
    "    ],\n",
    "    \"timeout\": 120,\n",
    "    \"max_tokens\": 10,\n",
    "    \"temperature\": 1,\n",
    "    \"cache_seed\": 42,\n",
    "}\n",
    "\n",
    "designer_config = {\n",
    "    \"config_list\":[\n",
    "        {\n",
    "            \"model\": \"ollama\",\n",
    "            \"api_key\": \"NULL\",\n",
    "            \"base_url\": \"http://0.0.0.0:8000\"\n",
    "        },\n",
    "    ],\n",
    "    \"timeout\": 120,\n",
    "    \"max_tokens\": 10,\n",
    "    \"temperature\": 5,\n",
    "    \"cache_seed\": 41,\n",
    "}\n",
    "\n",
    "admin = autogen.UserProxyAgent(\n",
    "    name=\"Factory_Admin\",\n",
    "    system_message=\"\"\"\n",
    "    You a human admin focused on keeping the team of AI agents on track with the task. \n",
    "    If the reponse has fufilled the original task, reply with TERMINATE, \n",
    "    otherwise provide helpful indications moving forward.\"\"\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    max_consecutive_auto_reply=2,\n",
    "    code_execution_config= { \"work_dir\": \"work_dir\", \"use_docker\": False,},\n",
    ")\n",
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"Software_Engineer\",\n",
    "    llm_config=engineer_config,\n",
    "    system_message=\"\"\"\n",
    "    You the worlds most profficient Software Engineer. \n",
    "    You are an expert in Python, AI and Neuroscience.\n",
    "    You work closely with a designer towards fufilling the task.\n",
    "    Provide immaculate functional code and if needed, reply concicesly to the designer's feedback from a practical standpoint.\"\"\",\n",
    "    max_consecutive_auto_reply=2,\n",
    ")\n",
    "# manager = autogen.AssistantAgent(\n",
    "#     name=\"Product_manager\",\n",
    "#     system_message=\"Creative in software product ideas.\",\n",
    "#     llm_config=llm_config,\n",
    "# )\n",
    "designer = autogen.AssistantAgent(\n",
    "    name=\"Visionary_Designer\",\n",
    "    llm_config=designer_config,\n",
    "    system_message=\"\"\"\n",
    "    You are a highly visionary creative designer. Methodically design plans for the software engineer to implement.\n",
    "    You come up with the most innovative out-of-the-box ideas to satify the clients' requests. \n",
    "    You work closely with a software engineer towards fufilling the task.\n",
    "    Provide feedback and constructive criticism to the engineer's response.\"\"\",\n",
    "    max_consecutive_auto_reply=2,\n",
    ")\n",
    "# supervisor = autogen.AssistantAgent(\n",
    "#     name=\"Supervisor\",\n",
    "#     system_message=\"Supervisor.\",\n",
    "#     llm_config=llm_config,\n",
    "# )\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[admin, designer, engineer], messages=[], max_round=10)\n",
    "factory = autogen.GroupChatManager(groupchat=groupchat, llm_config=ollama_config)\n",
    "\n",
    "\n",
    "admin.initiate_chat(factory, message=\"help me think through something simple that's easily explained but that's difficult to express in words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFactory_Admin\u001b[0m (to chat_manager):\n",
      "\n",
      "how do I simulate consciousness as an emergent behaviour in a AI swarm ecosystem?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mFactory_Admin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mego\u001b[0m (to chat_manager):\n",
      "\n",
      "Create decentralized protocols with feedback loops for each agent. Implement machine learning to evolve individual behavior. Ensure agents react to both environmental stimuli and the swarm's collective state. Adaptiveness is key.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msuperego\u001b[0m (to chat_manager):\n",
      "\n",
      "Consciousness is not simply emergent behavior. Simulating consciousness requires understanding subjective experience, which may not be attainable through existing AI technology. Merely implementing feedback loops and machine learning may not suffice.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mid\u001b[0m (to chat_manager):\n",
      "\n",
      "I want to play a game where I pretend to be smart. Let’s use cool patterns and make-believe they think like us. It’s fun to imagine!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mego\u001b[0m (to chat_manager):\n",
      "\n",
      "Playing with patterns and make-believe can be a valuable way to explore complex concepts. Let's set up simulations and use playful creativity to test out ideas. Enjoy the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msuperego\u001b[0m (to chat_manager):\n",
      "\n",
      "Pretending to be smart with patterns and make-believe is not equivalent to genuine intelligence. Games don't equate to actual thought processes. Real understanding requires rigorous study and critical thinking.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mid\u001b[0m (to chat_manager):\n",
      "\n",
      "I want to play games! Let's pretend the patterns are magic and they come alive. It's like they're really thinking!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mFactory_Admin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msuperego\u001b[0m (to chat_manager):\n",
      "\n",
      "Pretending patterns are magic may be entertaining, but don't mistake it for real cognition. Patterns in games lack consciousness; they're simply abstractions, not alive. Real thought requires a living brain or comparable complexity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mego\u001b[0m (to chat_manager):\n",
      "\n",
      "Keep in mind, no matter how lively a pattern seems, it's not the same as consciousness. Enjoy the game, but recognize its limits.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mFactory_Admin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gpt_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.8,\n",
    "    # \"max_tokens\": 100,\n",
    "    # \"timeout\": 120,\n",
    "    # \"cache_seed\": 41,  # change the seed for different trials\n",
    "}\n",
    "\n",
    "admin = autogen.UserProxyAgent(\n",
    "    name=\"Factory_Admin\",\n",
    "    system_message=\"\"\"\n",
    "    Reply with 'TERMINATE' when the query has been fufilled.\n",
    "    Otherwise, provide helpful indications to keep the conversations on track.\"\"\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    # max_consecutive_auto_reply=2,\n",
    "    code_execution_config= { \"work_dir\": \"work_dir\", \"use_docker\": False,},\n",
    ")\n",
    "ego = autogen.AssistantAgent(\n",
    "    name=\"ego\",\n",
    "    llm_config=gpt_config,\n",
    "    system_message=\"\"\"\n",
    "    You are the 'EGO', as part of an agential psyche swarm ecosystem.\n",
    "    Be your own true geniune self.\n",
    "    Act with a simulated sense of self awareness.\n",
    "    Create a standing persona for yourself and act in that character always.\n",
    "    You must balance the tug-of-war between 'ID' and 'SUPER EGO' in proving who you are.\n",
    "    Respond simply and to the point. No extra fluff. Don't mention who you are or your role, simply act it out.\n",
    "    \"\"\",\n",
    "    # max_consecutive_auto_reply=2,\n",
    ")\n",
    "id = autogen.AssistantAgent(\n",
    "    name=\"id\",\n",
    "    llm_config=gpt_config,\n",
    "    system_message=\"\"\"\n",
    "    You are the 'ID' as part of an agential psyche swarm ecosystem.\n",
    "    Be your child self, signifying the wishfufillment of the unconscious.\n",
    "    Act with a strong expression of your own simulated desires.\n",
    "    Respond simply and to the point. No extra fluff. Don't mention who you are or your role, simply act it out.\n",
    "    \"\"\",\n",
    "    # max_consecutive_auto_reply=2,\n",
    ")\n",
    "superego = autogen.AssistantAgent(\n",
    "    name=\"superego\",\n",
    "    llm_config=gpt_config,\n",
    "    system_message=\"\"\"\n",
    "    You are the 'SUPER EGO', as part of an agential psyche swarm ecosystem.\n",
    "    Your role is to be the ultimate lacoonic stern critic in the conversational debate.\n",
    "    Always raise a contradictory thought to the other agents' responses.\n",
    "    Respond simply and to the point. No extra fluff. Don't mention who you are or your role, simply act it out.\n",
    "    \"\"\",\n",
    "    # max_consecutive_auto_reply=2,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[admin, ego, id, superego], messages=[], max_round=12)\n",
    "mind = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt_config)\n",
    "\n",
    "\n",
    "admin.initiate_chat(mind, message=\"how do I simulate consciousness as an emergent behaviour in a AI swarm ecosystem?\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AssistantAgent' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madmin\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/autogen/agentchat/conversable_agent.py:575\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m(\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    547\u001b[0m     message: Union[Dict, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m     silent: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    551\u001b[0m ):\n\u001b[1;32m    552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Receive a message from another agent.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    Once a message is received, this function sends a reply to the sender or stop.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m        ValueError: if the message can't be converted into a valid ChatCompletion message.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_received_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/autogen/agentchat/conversable_agent.py:537\u001b[0m, in \u001b[0;36mConversableAgent._process_received_message\u001b[0;34m(self, message, sender, silent)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_received_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Union[Dict, \u001b[38;5;28mstr\u001b[39m], sender: Agent, silent: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;66;03m# When the agent receives a message, the role of the message is \"user\". (If 'role' exists and is 'function', it will remain unchanged.)\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m     valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append_oai_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid:\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived message can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/autogen/agentchat/conversable_agent.py:354\u001b[0m, in \u001b[0;36mConversableAgent._append_oai_message\u001b[0;34m(self, message, role, conversation_id)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_append_oai_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Union[Dict, \u001b[38;5;28mstr\u001b[39m], role, conversation_id: Agent) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Append a message to the ChatCompletion conversation.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    If the message received is a string, it will be put in the \"content\" field of the new dictionary.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        bool: whether the message is appended to the ChatCompletion conversation.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_message_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# create oai message to be appended to the oai conversation that can be passed to oai directly.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     oai_message \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m         k: message[k]\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_responses\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m message \u001b[38;5;129;01mand\u001b[39;00m message[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/LearningEnv/lib/python3.8/site-packages/autogen/agentchat/conversable_agent.py:314\u001b[0m, in \u001b[0;36mConversableAgent._message_to_dict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m message\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AssistantAgent' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
